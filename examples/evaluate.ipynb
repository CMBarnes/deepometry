{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os.path\n",
    "\n",
    "import numpy\n",
    "\n",
    "import deepometry.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate\n",
    "\n",
    "After training a model to classify single cell images, it is often useful to evaluate the performance of the model on an unseen annotated dataset. Evaluation helps predict model performance on unseen data.\n",
    "\n",
    "Suppose we have the following directory structure where images from one experiment (`experiment_02`) have been classified as one of three classes (`class_A`, `class_B`, or `class_C`). Data from this experiment was not shown to the model during training. Images are saved as NPY files:\n",
    "\n",
    "    /data/\n",
    "        experiment_02/\n",
    "            class_A/\n",
    "                32e88e1ac3a8f44bf8f77371155553b9.npy\n",
    "                3dc56a0c446942aa0da170acfa922091.npy  \n",
    "                ...\n",
    "            class_B/\n",
    "                8068ef7dcddd89da4ca9740bd2ccb31e.npy\n",
    "                8348deaa70dfc95c46bd02984d28b873.npy\n",
    "                ...\n",
    "            class_C/  \n",
    "                c1ecbca7bd98c01c1d3293b64cd6739a.npy\n",
    "                c56cfb8e7e7121dd822e47c67d07e2d4.npy\n",
    "                ...\n",
    "                \n",
    "\n",
    "The data can be used to evaluate a model for classifying image data as one of the three classes. The `collect_pathnames` and `load` functions defined below will select images to use for evaluating the model and generate the labels for the evaluation images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def collect_pathnames(directories):\n",
    "    \"\"\"\n",
    "    :param directories: List of directories to select samples from. Assumes subdirectories of each directory\n",
    "                        correspond to class labels. Contents of subdirectories are NPY files containing data\n",
    "                        of that label.\n",
    "    :return: List of pathnames.\n",
    "    \"\"\"\n",
    "    pathnames = []\n",
    "\n",
    "    for directory in directories:\n",
    "        subdirectories = glob.glob(os.path.join(directory, \"*\"))\n",
    "\n",
    "        pathnames += [glob.glob(os.path.join(subdirectory, \"*\")) for subdirectory in subdirectories]\n",
    "\n",
    "    return sum(pathnames, [])\n",
    "\n",
    "\n",
    "def load(pathnames, labels):\n",
    "    \"\"\"\n",
    "    Load training and target data.\n",
    "    \n",
    "    Assumes data is stored in a directory corresponding to some class label.\n",
    "\n",
    "    :param pathnames: List of image pathnames.\n",
    "    :param labels: List of class labels.\n",
    "    :return: Tuple (training, target) data, as NumPy arrays.\n",
    "    \"\"\"\n",
    "    x = numpy.empty((len(pathnames),) + _shape(pathnames[0]), dtype=numpy.uint8)\n",
    "\n",
    "    y = numpy.empty((len(pathnames),), dtype=numpy.uint8)\n",
    "\n",
    "    label_to_index = {label: index for index, label in enumerate(sorted(labels))}\n",
    "\n",
    "    for index, pathname in enumerate(pathnames):\n",
    "        label = os.path.split(os.path.dirname(pathname))[-1]\n",
    "\n",
    "        x[index] = numpy.load(pathname)\n",
    "\n",
    "        y[index] = label_to_index[label]\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def _shape(pathname):\n",
    "    \"\"\"\n",
    "    Infer the shape of the sample data from a single sample.\n",
    "    \n",
    "    :param pathname: Path to a sample.\n",
    "    :return: Sample dimensions.\n",
    "    \"\"\"\n",
    "    return numpy.load(pathname).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "directories = [\"/data/experiment_00\", \"/data/experiment_00\"]\n",
    "\n",
    "labels = [\"class_A\", \"class_B\", \"class_C\"]\n",
    "\n",
    "pathnames = collect_pathnames(directories)\n",
    "\n",
    "x, y = load(pathnames, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evaluation and target data (`x` and `y`, respectively) is next passed to the model for evaluation. **A previously trained model is required.** The `evaluate` method loads the trained model weights. See the `fit` notebook for instructions on training a model. \n",
    "\n",
    "Evaluation data is provided to the model in batches of 32 samples. Use `batch_size` to configure the number of samples. A smaller `batch_size` requires less memory.\n",
    "\n",
    "The evaluate function outputs the model's loss and accuracy metrics as the array `[loss, accuracy]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = deepometry.model.Model(shape=x.shape[1:], units=len(numpy.unique(y)))\n",
    "\n",
    "model.compile()\n",
    "\n",
    "model.evaluate(x, y, batch_size=32, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
